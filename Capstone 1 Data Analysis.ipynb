{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 34px; margin-bottom: 2px; line-height: 0px;\">AirBnB - Capstone Project 1 Data Analysis</h1>\n",
    "<h3 style=\"line-height: 2px; font-style: italic;\"> Timothy Baney<h3>\n",
    "\n",
    "* <a href=\"#intro\" style=\"color: black; text-decoration: none;\">Introduction</a>\n",
    "* <a href=\"#import\" style=\"color: black; text-decoration: none;\">Import Libraries</a>\n",
    "* <a href=\"#feat-eng-map\" style=\"color: black; text-decoration: none;\">Feature Engineering</a>\n",
    "    * <a href=\"#feat-eng-map\" style=\"color: black; text-decoration: none;\">Create Mapping functions</a>\n",
    "    * <a href=\"#feat-eng-oh\" style=\"color: black; text-decoration: none;\">One Hot Encoding</a>\n",
    "* <a href=\"#missing-values\" style=\"color: black; text-decoration: none;\">Handle Missing Values</a>\n",
    "* <a href=\"#over-sample\" style=\"color: black; text-decoration: none;\">Over Sample Minority Classes</a>\n",
    "* <a href=\"#holdout-data\" style=\"color: black; text-decoration: none;\">Create Holdout Data</a>\n",
    "* <a href=\"#init-models\" style=\"color: black; text-decoration: none;\">Initiate Scikit Learn Algorithm Classes</a>\n",
    "* <a href=\"#scoring-function\" style=\"color: black; text-decoration: none;\">Create Scoring Function</a>\n",
    "* <a href=\"#baseline-normal\" style=\"color: black; text-decoration: none;\">Create Baselines for All Algorithms</a>\n",
    "* <a href=\"#baseline-over\" style=\"color: black; text-decoration: none;\">Create Baselines for Over-sampled Data</a>\n",
    "* <a href=\"#hyp-knn\" style=\"color: black; text-decoration: none;\">Hyper Parameter Tuning</a>\n",
    "    * <a href=\"#hyp-knn\" style=\"color: black; text-decoration: none;\">KNN</a>\n",
    "    * <a href=\"#hyp-dtree\" style=\"color: black; text-decoration: none;\">Decision Trees</a>\n",
    "    * <a href=\"#hyp-rf\" style=\"color: black; text-decoration: none;\">Random Forests</a>\n",
    "    * <a href=\"#hyp-lr\" style=\"color: black; text-decoration: none;\">Logistic Regression</a>\n",
    "    * <a href=\"#hyp-grd\" style=\"color: black; text-decoration: none;\">Gradient Boosting</a>\n",
    "* <a href=\"#init-tuned\" style=\"color: black; text-decoration: none;\">Initialize Tuned Algorithms</a>\n",
    "* <a href=\"#feature-selection\" style=\"color: black; text-decoration: none;\">Perform Feature Selection</a>\n",
    "* <a href=\"#final-results\" style=\"color: black; text-decoration: none;\">Final Results</a>\n",
    "* <a href=\"#make-predictions\" style=\"color: black; text-decoration: none;\">Make Predictions</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p id=\"intro\" style=\"margin-bottom: 0px; line-height: 1px;\">Introduction</p>\n",
    "For this notebook, I am going to take the cleansed data that I have explored, and analyze how different machine learning algorithms perform on fitting a prediction model. I will first engineer the data so only key features are kept, and to make sure everything is numerical. I will then split my data to get a holdout set, train several algorithms, and than score them with cross validation using 10 folds to compare the algorithms with respect to their scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p id=\"import\">Import Libraries</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import random\n",
    "import pylab\n",
    "import math\n",
    "import itertools\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pylab as pylab\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from sklearn import datasets, tree, metrics, model_selection\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV as GSCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Perceptron\n",
    "from sklearn.feature_selection import SelectKBest, chi2, VarianceThreshold, RFE, RFECV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from spark_sklearn import GridSearchCV\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "# sc = pyspark.SparkContext()\n",
    "\n",
    "ucb = pd.read_csv('clean_airbnb.csv')\n",
    "test = pd.read_csv('airbnb_test.csv')\n",
    "user_ids = test['id'].values\n",
    "\n",
    "pylab.rcParams[ 'figure.figsize' ] = 15 , 10\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "new_style = {'grid': False}\n",
    "plt.rc('axes', **new_style)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p id=\"feat-eng-map\">Feature Engineering - Create Mapping Functions </p>\n",
    "Part of the feature engineering will include making functions to take multiple features in a column, and to return a new feature. One will get the time difference in days between signing up on the AirBnB site, and the users' first booking. Another will convert the date of the users' first booking, and return the season that the booking was made in. The others will see if the user language preference matches the destinations native language, and narrow all first browsers used to the top six browsers, and one browser titled 'other' to handle all other browsers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getTopBrowsers(row):\n",
    "    top_browsers = ['Chrome', 'Safari', 'Firefox', 'IE', 'Mobile Safari']\n",
    "    \n",
    "    if row['first_browser'] not in top_browsers:\n",
    "        return 'Other'\n",
    "    else:\n",
    "        return row['first_browser']\n",
    "    \n",
    "def getLapsedTime(row):\n",
    "    try:\n",
    "        account_creation = datetime.datetime.strptime(row['date_account_created'], '%Y-%m-%d')\n",
    "        first_booking = datetime.datetime.strptime(row['date_first_booking'], '%Y-%m-%d')\n",
    "        time_delta = first_booking - account_creation\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(row['id'])\n",
    "    \n",
    "    return time_delta.days\n",
    "\n",
    "lang_dict = {'en': 'eng', 'fr': 'fra', 'it': 'ita', 'es': 'spa', 'de': 'deu', 'nl': 'nld', 'pt': 'por'}\n",
    "\n",
    "def convertLang(row):\n",
    "    if row['language'] in lang_dict:\n",
    "        return lang_dict[row['language']]\n",
    "    else:\n",
    "        return row['language']\n",
    "    \n",
    "ucb['language'] = ucb.apply(lambda x: convertLang(x), axis=1)\n",
    "\n",
    "def langPrefMatch(row):\n",
    "    if row['language'] == row['destination_language ']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def getSeason(row):\n",
    "    seasons = {\n",
    "        '01': 'Winter',\n",
    "        '02': 'Winter',\n",
    "        '03': 'Spring',\n",
    "        '04': 'Spring',\n",
    "        '05': 'Spring',\n",
    "        '06': 'Summer',\n",
    "        '07': 'Summer',\n",
    "        '08': 'Summer',\n",
    "        '09': 'Autumn',\n",
    "        '10': 'Autumn',\n",
    "        '11': 'Autumn',\n",
    "        '12': 'Winter'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        return seasons[str(row['date_first_booking']).split('-')[1]]\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def fillMissingGender(row):\n",
    "    genders = ['MALE', 'FEMALE']\n",
    "    if row['gender'] != 'MALE' and row['gender'] != 'FEMALE':\n",
    "        return random.choice(genders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p id=\"feat-eng-oh\">Feature Engineering - One Hot Encoding</p>\n",
    "Before analyzing performance with various algorithms, it is important that we turn all of our categorical data into one hot encoding values. One hot encoding takes all the category values of a column, and makes them all their own unique column with a boolean value, a one, or a zero, that says whether or not that row is, or is not that category class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove all ghost rows \"Ones without IDs\"\n",
    "ucb = ucb[~ucb['id'].isnull()]\n",
    "\n",
    "# Remove Country Destination One Hot Values used in Data Story\n",
    "ucb = ucb.drop(['US', 'FR', 'IT', 'GB', 'ES', 'CA', 'DE', 'NL', 'AU', 'PT'], axis=1)\n",
    "\n",
    "# Remove rows where the user never booked a trip, since this won't provide any value for \n",
    "# Country predictions\n",
    "ucb = ucb.loc[ucb['country_destination'] != 'NDF']\n",
    "\n",
    "# Create Language Matches Column\n",
    "ucb['lang_match'] = ucb.apply(lambda x: langPrefMatch(x), axis=1)\n",
    "\n",
    "# Remove attributes that are directly related to the country e.g. Latitude, Longitude\n",
    "ucb = ucb.drop(['lat_destination', 'lng_destination', 'timestamp_first_active'], axis=1)\n",
    "ucb = ucb.drop(['language_levenshtein_distance', 'id'], axis=1)\n",
    "ucb = ucb.drop(['language', 'destination_language ', 'destination_km2', 'distance_km'], axis=1)\n",
    "\n",
    "test = test.drop(['timestamp_first_active', 'id', 'language'], axis=1)\n",
    "\n",
    "# Create Season Booked One Hot Columns [Autumn, Winter, Spring, Summer]\n",
    "ucb['season_booked'] = ucb.apply(lambda x: getSeason(x), axis=1)\n",
    "\n",
    "# Turn Seasons into one hot encoding values\n",
    "season = pd.get_dummies(ucb['season_booked'])\n",
    "ucb = ucb.join(season)\n",
    "ucb = ucb.drop('season_booked', axis=1)\n",
    "\n",
    "# Get most prevalant browsers used, labeling all other browsers as other\n",
    "ucb['first_browser'] = ucb.apply(lambda x: getTopBrowsers(x), axis=1)\n",
    "test['first_browser'] = ucb.apply(lambda x: getTopBrowsers(x), axis=1)\n",
    "\n",
    "# Turn gender into one hot encoding values \"Male, Female\"\n",
    "ucb = ucb[(ucb['gender'] == 'male') | (ucb['gender'] == 'female')]\n",
    "gender_oh = pd.get_dummies(ucb['gender'])\n",
    "ucb = ucb.join(gender_oh)\n",
    "ucb = ucb.drop('gender', axis=1)\n",
    "\n",
    "test['gender'] = test.apply(lambda x: fillMissingGender(x), axis=1)\n",
    "test_gender_oh = pd.get_dummies(test['gender'])\n",
    "test = test.join(test_gender_oh)\n",
    "test = test.drop('gender', axis=1)\n",
    "test = test.rename(columns={'MALE': 'male', 'FEMALE': 'female'})\n",
    "\n",
    "# Turn signup method into one hot encoding values\n",
    "su_method = pd.get_dummies(ucb['signup_method'])\n",
    "ucb = ucb.join(su_method)\n",
    "ucb = ucb.drop('signup_method', axis=1)\n",
    "ucb = ucb.rename(columns={'basic': 'signup_basic', 'facebook': 'signup_facebook', 'google': 'signup_google'})\n",
    "\n",
    "test_su_method = pd.get_dummies(test['signup_method'])\n",
    "test = test.join(test_su_method)\n",
    "test = test.drop('signup_method', axis=1)\n",
    "test = test.rename(columns={'basic': 'signup_basic', 'facebook': 'signup_facebook', 'google': 'signup_google'})\n",
    "\n",
    "# Turn signup app into one hot encoding values\n",
    "su_app = pd.get_dummies(ucb['signup_app'])\n",
    "ucb = ucb.join(su_app)\n",
    "ucb = ucb.drop('signup_app', axis=1)\n",
    "\n",
    "test_su_app = pd.get_dummies(test['signup_app'])\n",
    "test = test.join(test_su_app)\n",
    "test = test.drop('signup_app', axis=1)\n",
    "\n",
    "# Turn first device type into one hot encoding values\n",
    "dev_type = pd.get_dummies(ucb['first_device_type'])\n",
    "ucb = ucb.join(dev_type)\n",
    "ucb = ucb.drop('first_device_type', axis=1)\n",
    "\n",
    "test_dev_type = pd.get_dummies(test['first_device_type'])\n",
    "test = test.join(test_dev_type)\n",
    "test = test.drop('first_device_type', axis=1)\n",
    "\n",
    "# Turn affiliate channel into one hot encoding values\n",
    "af_channel = pd.get_dummies(ucb['affiliate_channel'])\n",
    "ucb = ucb.join(af_channel)\n",
    "ucb = ucb.drop('affiliate_channel', axis=1)\n",
    "ucb = ucb.rename(columns={'api': 'ch_api', 'content': 'ch_content', 'direct': 'ch_direct',\n",
    "                          'other': 'ch_other', 'remarketing': 'ch_remarketing', 'sem-brand': 'ch_sem_brand',\n",
    "                          'sem-non-brand': 'ch_sem_non_brand', 'seo': 'ch_seo'})\n",
    "\n",
    "test_af_channel = pd.get_dummies(test['affiliate_channel'])\n",
    "test = test.join(test_af_channel)\n",
    "test = test.drop('affiliate_channel', axis=1)\n",
    "test = test.rename(columns={'api': 'ch_api', 'content': 'ch_content', 'direct': 'ch_direct',\n",
    "                          'other': 'ch_other', 'remarketing': 'ch_remarketing', 'sem-brand': 'ch_sem_brand',\n",
    "                          'sem-non-brand': 'ch_sem_non_brand', 'seo': 'ch_seo'})\n",
    "\n",
    "# Turn affiliate provider into one hot encoding values\n",
    "af_provider = pd.get_dummies(ucb['affiliate_provider'])\n",
    "ucb = ucb.join(af_provider)\n",
    "ucb = ucb.drop('affiliate_provider', axis=1)\n",
    "\n",
    "test_af_provider = pd.get_dummies(test['affiliate_provider'])\n",
    "test = test.join(test_af_provider)\n",
    "test = test.drop('affiliate_provider', axis=1)\n",
    "\n",
    "# Turn first affiliate tracked into one hot encoding values\n",
    "fa_oh = pd.get_dummies(ucb['first_affiliate_tracked'])\n",
    "ucb = ucb.join(fa_oh)\n",
    "ucb = ucb.drop('first_affiliate_tracked', axis=1)\n",
    "\n",
    "test_fa_oh = pd.get_dummies(test['first_affiliate_tracked'])\n",
    "test = test.join(test_fa_oh)\n",
    "test = test.drop('first_affiliate_tracked', axis=1)\n",
    "\n",
    "# Turn first browser into one hot encoding values\n",
    "fbwsr_oh = pd.get_dummies(ucb['first_browser'])\n",
    "ucb = ucb.join(fbwsr_oh)\n",
    "ucb = ucb.drop('first_browser', axis=1)\n",
    "\n",
    "test_fbwsr_oh = pd.get_dummies(test['first_browser'])\n",
    "test = test.join(test_fbwsr_oh)\n",
    "test = test.drop('first_browser', axis=1)\n",
    "\n",
    "# Create 'AccountCreation-BookingTime' column for difference\n",
    "ucb['days_to_book'] = ucb.apply(lambda x: getLapsedTime(x), axis=1)\n",
    "\n",
    "# Remove date_account_created, and first_booking columns\n",
    "ucb = ucb.drop(['date_account_created', 'date_first_booking'], axis=1)\n",
    "test = test.drop('date_account_created', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test['age'] = test['age'].mean()\n",
    "test = test.drop('date_first_booking', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p id=\"missing-values\">Handle Missing Values</p>\n",
    "Our data still has some missing values. to fix this we will simply remove the rows with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ucb = ucb.loc[~ucb['actions_total_count'].isnull()]\n",
    "ucb = ucb.loc[~ucb['average_action_duration'].isnull()]\n",
    "ucb = ucb.loc[~ucb['dest_age_pop'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p id=\"over-sample\">Over Sample Minority Classes</p>\n",
    "The target class has 10 categories, each a different country. The United States has far more occurences than the other countries so it is imbalanced, and will force our predictions to be mainly US. We may get a misleading high accuracy rate if the every single prediction is 'US'. To remedy this, we will do a few things. First I will not only get a 10 fold cross validation score for each algorithm, but will also get the true positive rate for each country using a confusiong matrix so we can score each individual country. I will also create a new dataset, using a strategy called over-sampling. The idea is simple. For minority classes, we can resample from the minority classes, and add new minority class occurences to the main data to even the playing field so to speak. You can under-sample majority classes, and over-sample minority classes, but for smaller datasets \"anything in the tens of thousands or less\", it is recommended to use over-sampling. I am using SMOTE \"Synthetic Minority Over-sampling Technique' to over sample my minority classes. ** This takes a considerable amount of time to do, so I have saved the resulting dataset, and simply referenced it using Panda's .read_csv **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def overSampleMinority(df, minority):\n",
    "    # Get all rows that are USA or minority, i.e. France\n",
    "    # SMOTE will oversample French samples to match USA\n",
    "    df = df[(df['US'] == 1) | (df[minority] == 1)]\n",
    "    \n",
    "    X = df.drop(['country_destination', 'US'], axis=1)\n",
    "    y = df['US'].values\n",
    "    \n",
    "    cols = X.columns\n",
    "\n",
    "    # Resample Data, Matching\n",
    "    X_res, y_res = SMOTE(kind='regular').fit_sample(X, y)\n",
    "    \n",
    "    age = [X_res[row][0] for row in range(0, len(X_res))]\n",
    "    \n",
    "    resampled = pd.DataFrame(columns=df.columns)\n",
    "    for res in range(1, len(X_res)):\n",
    "        obj = {}\n",
    "        for index, col in enumerate(cols):            \n",
    "            obj[col] = X_res[res][index]\n",
    "            obj['US'] = y_res[res]\n",
    "        \n",
    "        new_row = pd.Series(obj)\n",
    "        resampled = resampled.append(new_row, ignore_index=True)\n",
    "    \n",
    "    return resampled[resampled[minority] == 1]\n",
    "\n",
    "# france = overSampleMinority(ucb_ofit, 'FR')\n",
    "# italy = overSampleMinority(ucb_ofit, 'IT')\n",
    "# denmark = overSampleMinority(ucb_ofit, 'DE')\n",
    "# australia = overSampleMinority(ucb_ofit, 'AU')\n",
    "# portugal = overSampleMinority(ucb_ofit, 'PT')\n",
    "# spain = overSampleMinority(ucb_ofit, 'ES')\n",
    "# canada = overSampleMinority(ucb_ofit, 'CA')\n",
    "# great_britain = overSampleMinority(ucb_ofit, 'GB')\n",
    "# netherlands = overSampleMinority(ucb_ofit, 'NL')\n",
    "# usa = ucb[ucb['country_destination'] == 'US']\n",
    "\n",
    "# overSampledUcb = france.append(italy)\n",
    "# overSampledUcb = overSampledUcb.append(denmark)\n",
    "# overSampledUcb = overSampledUcb.append(australia)\n",
    "# overSampledUcb = overSampledUcb.append(portugal)\n",
    "# overSampledUcb = overSampledUcb.append(spain)\n",
    "# overSampledUcb = overSampledUcb.append(canada)\n",
    "# overSampledUcb = overSampledUcb.append(great_britain)\n",
    "# overSampledUcb = overSampledUcb.append(netherlands)\n",
    "# overSampledUcb = overSampledUcb.append(usa)\n",
    "\n",
    "os_ucb = pd.read_csv('over_sample_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p id=\"holdout-data\">Create Holdout Data</p>\n",
    "The get a more accurate scoring of the algorithms used, we will seperate our data by a 30/70 split, the 30% being the 'holdout' data. The holdout data isn't used to train any models, and doesn't include the target feature, so it simulates unseen data to the model. We will also cross validate on ten folds to ensure the most precise measure of performance for each algorithm we can. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "country_names = ['GLOBAL', 'AU', 'CA', 'DE', 'SP', 'FR', 'GB', 'IT', 'NL', 'PT', 'US']\n",
    "\n",
    "X = ucb.drop('country_destination', axis=1)\n",
    "y = ucb['country_destination'].values\n",
    "\n",
    "osX = os_ucb.drop('country_destination', axis=1)\n",
    "osY = os_ucb['country_destination'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state=42, stratify=y)\n",
    "osX_train, osX_test, osy_train, osy_test = train_test_split(osX, osY, test_size = .3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p id=\"init-models\">Initiate Scikit Learn Algorithm Classes</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "dtree = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "logreg = LogisticRegression()\n",
    "gaus = GaussianNB()\n",
    "grd = GradientBoostingClassifier()\n",
    "per = Perceptron()\n",
    "voting = VotingClassifier(estimators=[('knn', knn), ('dtree', dtree), ('grd', grd)], voting='soft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p id=\"scoring-function\">Create Scoring Function</p>\n",
    "The function will take an algorithm as its only parameter, will fit the algorithm with the training data, score it with cross validation, and create a list of true positive matches for each class using a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scoreFit(alg, xt, yt, xtst, ytst):\n",
    "    alg.fit(xt, yt)\n",
    "    alg_fold_score = model_selection.cross_val_score(alg, xtst, ytst, cv=10).mean()\n",
    "    predictions = alg.predict(xtst)\n",
    "    c_matrix = confusion_matrix(ytst, predictions)\n",
    "    \n",
    "    country_tp_percent = []\n",
    "    for x in range(0, 10): # <= For row in matrix\n",
    "        row_total = 0\n",
    "        for y in range(0, 10): # <= For column in matrix\n",
    "            row_total += c_matrix[x, y]\n",
    "        country_tp_percent.append(c_matrix[x, x]/row_total)\n",
    "        \n",
    "    country_tp_percent = [alg_fold_score] + country_tp_percent\n",
    "    return country_tp_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p id=\"baseline-normal\">Create Baselines for All Algorithms </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN Score</th>\n",
       "      <th>Decision Trees Score</th>\n",
       "      <th>Random Forest Score</th>\n",
       "      <th>Logistric Regression Score</th>\n",
       "      <th>Gaussian NB Score</th>\n",
       "      <th>Gradient Boosting Score</th>\n",
       "      <th>Perceptron Score</th>\n",
       "      <th>Voting Ensemble Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.950006</td>\n",
       "      <td>0.986294</td>\n",
       "      <td>0.935673</td>\n",
       "      <td>0.895094</td>\n",
       "      <td>0.914416</td>\n",
       "      <td>0.990140</td>\n",
       "      <td>0.814826</td>\n",
       "      <td>0.989285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.903226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.311688</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.961039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.745098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.980392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.572581</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.588710</td>\n",
       "      <td>0.975806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.967347</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.987755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.633588</td>\n",
       "      <td>0.946565</td>\n",
       "      <td>0.938931</td>\n",
       "      <td>0.931298</td>\n",
       "      <td>0.938931</td>\n",
       "      <td>0.954198</td>\n",
       "      <td>0.198473</td>\n",
       "      <td>0.946565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.812903</td>\n",
       "      <td>0.922581</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.941935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.977778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.998152</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999736</td>\n",
       "      <td>0.996568</td>\n",
       "      <td>0.995776</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997888</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    KNN Score  Decision Trees Score  Random Forest Score  \\\n",
       "0    0.950006              0.986294             0.935673   \n",
       "1    0.903226              1.000000             0.290323   \n",
       "2    0.883117              0.961039             0.896104   \n",
       "3    0.745098              1.000000             0.313725   \n",
       "4    0.693548              0.967742             0.572581   \n",
       "5    0.914286              0.967347             0.938776   \n",
       "6    0.633588              0.946565             0.938931   \n",
       "7    0.812903              0.922581             0.600000   \n",
       "8    0.977778              1.000000             0.311111   \n",
       "9    1.000000              0.923077             0.000000   \n",
       "10   0.998152              1.000000             0.999736   \n",
       "\n",
       "    Logistric Regression Score  Gaussian NB Score  Gradient Boosting Score  \\\n",
       "0                     0.895094           0.914416                 0.990140   \n",
       "1                     0.161290           0.967742                 1.000000   \n",
       "2                     0.311688           0.922078                 0.961039   \n",
       "3                     0.000000           0.549020                 0.941176   \n",
       "4                     0.064516           0.588710                 0.975806   \n",
       "5                     0.914286           0.755102                 0.987755   \n",
       "6                     0.931298           0.938931                 0.954198   \n",
       "7                     0.012903           0.400000                 0.903226   \n",
       "8                     0.666667           0.911111                 0.977778   \n",
       "9                     0.153846           0.692308                 0.923077   \n",
       "10                    0.996568           0.995776                 1.000000   \n",
       "\n",
       "    Perceptron Score  Voting Ensemble Score  \n",
       "0           0.814826               0.989285  \n",
       "1           0.000000               1.000000  \n",
       "2           0.000000               0.961039  \n",
       "3           0.000000               0.980392  \n",
       "4           0.000000               0.983871  \n",
       "5           0.000000               0.983673  \n",
       "6           0.198473               0.946565  \n",
       "7           0.000000               0.941935  \n",
       "8           0.000000               1.000000  \n",
       "9           0.000000               0.923077  \n",
       "10          0.997888               1.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_scores = pd.DataFrame({\n",
    "    'KNN Score': scoreFit(knn, X_train, y_train, X_test, y_test)\n",
    "})\n",
    "\n",
    "dtree_scores = pd.DataFrame({\n",
    "    'Decision Trees Score': scoreFit(dtree, X_train, y_train, X_test, y_test)\n",
    "})\n",
    "\n",
    "rf_scores = pd.DataFrame({\n",
    "    'Random Forest Score': scoreFit(rf, X_train, y_train, X_test, y_test)\n",
    "})\n",
    "\n",
    "lr_scores = pd.DataFrame({\n",
    "    'Logistric Regression Score': scoreFit(logreg, X_train, y_train, X_test, y_test)\n",
    "})\n",
    "\n",
    "gaus_scores = pd.DataFrame({\n",
    "    'Gaussian NB Score': scoreFit(gaus, X_train, y_train, X_test, y_test)\n",
    "})\n",
    "\n",
    "grd_scores = pd.DataFrame({\n",
    "    'Gradient Boosting Score': scoreFit(grd, X_train, y_train, X_test, y_test)\n",
    "})\n",
    "\n",
    "per_scores = pd.DataFrame({\n",
    "    'Perceptron Score': scoreFit(per, X_train, y_train, X_test, y_test)\n",
    "})\n",
    "\n",
    "voting_scores = pd.DataFrame({\n",
    "    'Voting Ensemble Score': scoreFit(voting, X_train, y_train, X_test, y_test)\n",
    "})\n",
    "\n",
    "baseline_scores = knn_scores.join(dtree_scores)\n",
    "baseline_scores = baseline_scores.join(rf_scores)\n",
    "baseline_scores = baseline_scores.join(lr_scores)\n",
    "baseline_scores = baseline_scores.join(gaus_scores)\n",
    "baseline_scores = baseline_scores.join(grd_scores)\n",
    "baseline_scores = baseline_scores.join(per_scores)\n",
    "baseline_scores = baseline_scores.join(voting_scores)\n",
    "\n",
    "baseline_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p id=\"baseline-over\">Create Baselines for Over-sampled Data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>KNN Score</th>\n",
       "      <th>Decision Trees Score</th>\n",
       "      <th>Random Forest Score</th>\n",
       "      <th>Logistric Regression Score</th>\n",
       "      <th>Gaussian NB Score</th>\n",
       "      <th>Gradient Boosting Score</th>\n",
       "      <th>Perceptron Score</th>\n",
       "      <th>Voting Ensemble Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>0.994413</td>\n",
       "      <td>0.998390</td>\n",
       "      <td>0.997995</td>\n",
       "      <td>0.713634</td>\n",
       "      <td>0.796193</td>\n",
       "      <td>0.996120</td>\n",
       "      <td>0.196799</td>\n",
       "      <td>0.999184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AU</td>\n",
       "      <td>0.987382</td>\n",
       "      <td>0.996357</td>\n",
       "      <td>0.993902</td>\n",
       "      <td>0.710264</td>\n",
       "      <td>0.797963</td>\n",
       "      <td>0.995195</td>\n",
       "      <td>0.193269</td>\n",
       "      <td>0.997651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA</td>\n",
       "      <td>0.999220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974526</td>\n",
       "      <td>0.984923</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DE</td>\n",
       "      <td>0.998913</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.712694</td>\n",
       "      <td>0.947540</td>\n",
       "      <td>0.999728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP</td>\n",
       "      <td>0.998166</td>\n",
       "      <td>0.998166</td>\n",
       "      <td>0.997904</td>\n",
       "      <td>0.702306</td>\n",
       "      <td>0.736373</td>\n",
       "      <td>0.995807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FR</td>\n",
       "      <td>0.985989</td>\n",
       "      <td>0.996886</td>\n",
       "      <td>0.994292</td>\n",
       "      <td>0.444214</td>\n",
       "      <td>0.725221</td>\n",
       "      <td>0.991178</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GB</td>\n",
       "      <td>0.991632</td>\n",
       "      <td>0.995554</td>\n",
       "      <td>0.996077</td>\n",
       "      <td>0.282688</td>\n",
       "      <td>0.434362</td>\n",
       "      <td>0.991109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.997908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IT</td>\n",
       "      <td>0.983356</td>\n",
       "      <td>0.997047</td>\n",
       "      <td>0.999463</td>\n",
       "      <td>0.795705</td>\n",
       "      <td>0.955973</td>\n",
       "      <td>0.998658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NL</td>\n",
       "      <td>0.989002</td>\n",
       "      <td>0.996781</td>\n",
       "      <td>0.993830</td>\n",
       "      <td>0.264217</td>\n",
       "      <td>0.331277</td>\n",
       "      <td>0.984979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.997586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PT</td>\n",
       "      <td>0.999739</td>\n",
       "      <td>0.999739</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963485</td>\n",
       "      <td>0.950183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>US</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899844</td>\n",
       "      <td>0.999741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AVG</td>\n",
       "      <td>0.998117</td>\n",
       "      <td>0.999731</td>\n",
       "      <td>0.998386</td>\n",
       "      <td>0.996503</td>\n",
       "      <td>0.996235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967994</td>\n",
       "      <td>0.999731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country  KNN Score  Decision Trees Score  Random Forest Score  \\\n",
       "0   GLOBAL   0.994413              0.998390             0.997995   \n",
       "1       AU   0.987382              0.996357             0.993902   \n",
       "2       CA   0.999220              1.000000             1.000000   \n",
       "3       DE   0.998913              1.000000             1.000000   \n",
       "4       SP   0.998166              0.998166             0.997904   \n",
       "5       FR   0.985989              0.996886             0.994292   \n",
       "6       GB   0.991632              0.995554             0.996077   \n",
       "7       IT   0.983356              0.997047             0.999463   \n",
       "8       NL   0.989002              0.996781             0.993830   \n",
       "9       PT   0.999739              0.999739             1.000000   \n",
       "10      US   1.000000              1.000000             1.000000   \n",
       "11     AVG   0.998117              0.999731             0.998386   \n",
       "\n",
       "    Logistric Regression Score  Gaussian NB Score  Gradient Boosting Score  \\\n",
       "0                     0.713634           0.796193                 0.996120   \n",
       "1                     0.710264           0.797963                 0.995195   \n",
       "2                     0.974526           0.984923                 1.000000   \n",
       "3                     0.712694           0.947540                 0.999728   \n",
       "4                     0.702306           0.736373                 0.995807   \n",
       "5                     0.444214           0.725221                 0.991178   \n",
       "6                     0.282688           0.434362                 0.991109   \n",
       "7                     0.795705           0.955973                 0.998658   \n",
       "8                     0.264217           0.331277                 0.984979   \n",
       "9                     0.963485           0.950183                 1.000000   \n",
       "10                    1.000000           0.899844                 0.999741   \n",
       "11                    0.996503           0.996235                 1.000000   \n",
       "\n",
       "    Perceptron Score  Voting Ensemble Score  \n",
       "0           0.196799               0.999184  \n",
       "1           0.193269               0.997651  \n",
       "2           0.000000               1.000000  \n",
       "3           0.000000               1.000000  \n",
       "4           0.000000               0.998952  \n",
       "5           1.000000               0.997665  \n",
       "6           0.000000               0.997908  \n",
       "7           0.000000               1.000000  \n",
       "8           0.000000               0.997586  \n",
       "9           0.000000               1.000000  \n",
       "10          0.000000               1.000000  \n",
       "11          0.967994               0.999731  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_scores = pd.DataFrame({\n",
    "    'KNN Score': scoreFit(knn, osX_train, osy_train, osX_test, osy_test)\n",
    "})\n",
    "\n",
    "dtree_scores = pd.DataFrame({\n",
    "    'Decision Trees Score': scoreFit(dtree, osX_train, osy_train, osX_test, osy_test)\n",
    "})\n",
    "\n",
    "rf_scores = pd.DataFrame({\n",
    "    'Random Forest Score': scoreFit(rf, osX_train, osy_train, osX_test, osy_test)\n",
    "})\n",
    "\n",
    "lr_scores = pd.DataFrame({\n",
    "    'Logistric Regression Score': scoreFit(logreg, osX_train, osy_train, osX_test, osy_test)\n",
    "})\n",
    "\n",
    "gaus_scores = pd.DataFrame({\n",
    "    'Gaussian NB Score': scoreFit(gaus, osX_train, osy_train, osX_test, osy_test)\n",
    "})\n",
    "\n",
    "grd_scores = pd.DataFrame({\n",
    "    'Gradient Boosting Score': scoreFit(grd, osX_train, osy_train, osX_test, osy_test)\n",
    "})\n",
    "\n",
    "per_scores = pd.DataFrame({\n",
    "    'Perceptron Score': scoreFit(per, osX_train, osy_train, osX_test, osy_test)\n",
    "})\n",
    "\n",
    "voting_scores = pd.DataFrame({\n",
    "    'Voting Ensemble Score': scoreFit(voting, osX_train, osy_train, osX_test, osy_test)\n",
    "})\n",
    "\n",
    "oversample_scores = knn_scores.join(dtree_scores)\n",
    "oversample_scores = oversample_scores.join(rf_scores)\n",
    "oversample_scores = oversample_scores.join(lr_scores)\n",
    "oversample_scores = oversample_scores.join(gaus_scores)\n",
    "oversample_scores = oversample_scores.join(grd_scores)\n",
    "oversample_scores = oversample_scores.join(per_scores)\n",
    "oversample_scores = oversample_scores.join(voting_scores)\n",
    "\n",
    "oversample_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p id=\"hyp-knn\">Hyper Parameter Tuning - KNN</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nbrs = [num for num in range(1, 10)]\n",
    "lsize = [leaf for leaf in range(1, 100)]\n",
    "\n",
    "parameters = {'leaf_size': lsize, 'n_neighbors': nbrs, 'weights': ['uniform', 'distance'],\n",
    "              'algorithm': ['kd_tree']}\n",
    "\n",
    "clf = GridSearchCV(sc, knn, parameters).fit(X_train, y_train)\n",
    "clf.best_estimator_\n",
    "\n",
    "# Best Parameters:\n",
    "# leaf_size: 1\n",
    "# n_neighbors: 1\n",
    "# algorithm: 'kd_tree'\n",
    "# weights: 'uniform'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p id=\"hyp-dtree\">Hyper Parameter Tuning - Decision Trees</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_feat = [x for x in range(1, 100)]\n",
    "min_leaf = [x for x in range(1, 10)]\n",
    "\n",
    "parameters = {'criterion': ['gini', 'entropy'], 'splitter': ['best', 'random'], \n",
    "              'max_features': max_feat, 'min_samples_leaf': min_leaf,\n",
    "              'class_weight': ['balanced', 'None']}\n",
    "\n",
    "clf = GridSearchCV(sc, dtree, parameters).fit(X_train, y_train)\n",
    "best = clf.best_estimator_\n",
    "\n",
    "# min_samples_leaf: 1\n",
    "# criterion: 'entropy'\n",
    "# max_features: 48\n",
    "# splitter: 'best'\n",
    "# class_weight: 'balanced'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p id=\"hyp-rf\">Hyper Parameter Tuning - Random Forests</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_feat = [x for x in range(1, 100)]\n",
    "min_leaf = [x for x in range(1, 10)]\n",
    "estimators = [x for x in range(1, 200)]\n",
    "    \n",
    "parameters = {'n_estimators': estimators, 'criterion': ['gini', 'entropy'], \n",
    "              'max_features': max_feat, 'min_samples_leaf': min_leaf,\n",
    "              'class_weight': ['balanced', None], 'warm_start': [True, False], 'bootstrap': [True, False]}\n",
    "              \n",
    "clf = GridSearchCV(sc, rf, parameters).fit(X_train, y_train)\n",
    "best = clf.best_estimator_\n",
    "\n",
    "# N_estimators: 78\n",
    "# min_samples_leaf: 1\n",
    "# Bootstrap: False\n",
    "# Max Features: 69\n",
    "# Warm Start: False\n",
    "# class_weight: 'balanced\n",
    "# Criterion: 'Entropy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p id=\"hyp-lr\">Hyper Parameter Tuning -  Logistic Regression</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_i = [x for x in range(1, 100)]\n",
    "\n",
    "parameters = {'penalty': [11, 12], 'C': [.001, .01, .1, 1, 10, 100],  'fit_intercept': [True, False],\n",
    "              'solver': ['liblinear', 'newton-cg', 'sag', 'lbfgs'], 'max_iter': max_i,\n",
    "              'class_weight': ['balance', None], 'multi_class': ['ovr', 'multinomial']}\n",
    "              \n",
    "clf = GridSearchCV(sc, logreg, parameters).fit(X_train, y_train)\n",
    "best = clf.best_estimator_\n",
    "\n",
    "# Max_iter: 76\n",
    "# C: 1\n",
    "# solver: newton-cg\n",
    "# class_weight: balanced\n",
    "# multi_class: multinomial\n",
    "# penalty: 11\n",
    "# fit_intercept: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p id=\"hyp-grd\">Hyper Parameter Tuning - Gradient Boosting</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimators = [x for x in range(1, 50)]\n",
    "lrate = [x/1000 for x in range(1, 100)]\n",
    "min_leaf = [x for x in range(1, 60)]\n",
    "\n",
    "grd = GradientBoostingClassifier()\n",
    "\n",
    "parameters = {'learning_rate': lrate, 'n_estimators': estimators,\n",
    "              'max_features': ['log2', 'sqrt', range(1, 100)], 'min_samples_leaf': min_leaf}\n",
    "              \n",
    "clf = GridSearchCV(sc, grd, parameters).fit(X_train, y_train)\n",
    "best = clf.best_estimator_\n",
    "\n",
    "# n_estimators: 49\n",
    "# learning_Rate: .094\n",
    "# min_samples_leaf: 1\n",
    "# max_features: 55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p id=\"init-tuned\">Initialize Tuned Algorithms</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuned_knn = KNeighborsClassifier(leaf_size=1, n_neighbors=1, algorithm='kd_tree', weights='uniform')\n",
    "tuned_dtree = DecisionTreeClassifier(min_samples_leaf=1, criterion='entropy', splitter='best')\n",
    "tuned_rf = RandomForestClassifier(n_estimators=78, min_samples_leaf=1, bootstrap=False, warm_start=False, class_weight='balanced', criterion='entropy')\n",
    "tuned_logreg = LogisticRegression(max_iter=76, solver='newton-cg', class_weight='balanced', multi_class='multinomial')\n",
    "tuned_grd = GradientBoostingClassifier(n_estimators=49, learning_rate=.094, min_samples_leaf=1)\n",
    "tuned_voting = VotingClassifier(estimators=[('knn', tuned_knn), ('dtree', tuned_dtree), ('grd', tuned_grd)], voting='soft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p id=\"feature-selection\">Perform Feature Selection </p>\n",
    "\n",
    "The data being used has 60 features. This could be lead to overfitting. To remedy this, I am going to find the most important features for every algorithm using ** Recursive Feature Elimination (RFE)**. From the scikit learn website ** * Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and weights are assigned to each one of them. Then, features whose absolute weights are the smallest are pruned from the current set features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached. * **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getOptimalFeatures(alg):\n",
    "    scores = []\n",
    "    for feat_count in range(1, 60):\n",
    "        rfe_alg = RFE(estimator=alg, n_features_to_select=feat_count, step=1)\n",
    "        rfe_alg.fit(X_train, y_train)\n",
    "        rfe_score = rfe_alg.score(X_test, y_test)\n",
    "        print(feat_count)\n",
    "\n",
    "        scores.append({'feat_count': feat_count, 'score': rfe_score})\n",
    "        \n",
    "    scores = sorted(scores, key=lambda x: x['score'], reverse=True)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimal_knn = tuned_knn\n",
    "optimal_logreg = RFE(estimator=tuned_logreg, n_features_to_select=5, step=1)\n",
    "optimal_dtree = RFE(estimator=tuned_dtree, n_features_to_select=3, step=1)\n",
    "optimal_rf = RFE(estimator=tuned_rf, n_features_to_select=3, step=1)\n",
    "optimal_grd = RFE(estimator=tuned_grd, n_features_to_select=4, step=1)\n",
    "optimal_gaus = RFE(estimator=gaus, n_features_to_select=3, step=1)\n",
    "optimal_per = RFE(estimator=per, n_features_to_select=7, step=1)\n",
    "optimal_voting = VotingClassifier(estimators=[('optimal_knn', optimal_knn), ('optimal_dtree', optimal_dtree), ('optimal_grd', optimal_grd)], voting='soft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p id=\"final-results\">Final Results</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt_knn_scores = pd.DataFrame({\n",
    "    'Tuned KNN Score': scoreFit(optimal_knn, X_train, X_test, y_train, y_test)\n",
    "})\n",
    "opt_dt_scores = pd.DataFrame({\n",
    "    'Tuned Decision Tree Score': scoreFit(optimal_dtree, X_train, X_test, y_train, y_test)\n",
    "})\n",
    "opt_rf_scores = pd.DataFrame({\n",
    "    'Tuned Random Forest Score': scoreFit(optimal_rf, X_train, X_test, y_train, y_test)\n",
    "})\n",
    "opt_grd_scores = pd.DataFrame({\n",
    "    'Tuned Gradient Boosting Score': scoreFit(optimal_grd, X_train, X_test, y_train, y_test)\n",
    "})\n",
    "opt_gaus_scores = pd.DataFrame({\n",
    "    'Tuned Gaus Score': scoreFit(optimal_gaus, X_train, X_test, y_train, y_test)\n",
    "})\n",
    "opt_per_scores = pd.DataFrame({\n",
    "    'Tuned Perceptron Score': scoreFit(optimal_per, X_train, X_test, y_train, y_test)\n",
    "})\n",
    "opt_voting_scores = pd.DataFrame({\n",
    "    'Tuned Voting Score': scoreFit(optimal_voting, X_train,X_test, y_train, y_test)\n",
    "})\n",
    "all_scores = pd.DataFrame({\n",
    "    'Country': country_names\n",
    "})\n",
    "\n",
    "alg_scores = [knn_scores, opt_knn_scores, dtree_scores, opt_dt_scores, rf_scores, opt_rf_scores, lr_scores,\n",
    "gaus_scores, grd_scores, opt_grd_scores, per_scores, opt_per_scores, voting_scores, opt_voting_scores]\n",
    "\n",
    "for score in alg_scores:\n",
    "    all_scores = all_scores.join(score)\n",
    "    \n",
    "all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <p id=\"make-predictions\">Make Predictions</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test = test.drop('weibo', axis=1)\n",
    "test = test.drop('daum')\n",
    "X = ucb.drop('country_destination', axis=1)\n",
    "X = X[test.columns]\n",
    "y = ucb['country_destination'].values\n",
    "\n",
    "optimal_grd.fit(X, y)\n",
    "predictions = optimal_grd.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ------------ PREPARE FOR SUBMISSION -------------- #\n",
    "new_df = pd.DataFrame(columns=['id', 'country'])\n",
    "new_df['id'] = user_ids\n",
    "new_df['country'] = predictions\n",
    "new_df.to_csv('airbnb_final.csv', index=False)\n",
    "# ---------- END PREPARE FOR SUBMISSION ----------- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p id=\"summary\">Summary</p>\n",
    "After submitting my predictions to the Kaggle competition with the imbalanced dataset I received a 23%. This was actually because a hundred percent of my predictions were 'US', so it was simply getting every 'US' right. I than fit the same algorithm with the data from the over-sampled minority classes, and received an even lower score, 21%. Considering my global ten fold cross validation scores for each algorithm, and true positive scores for each class for each algorithm were very high, I am highly surprised that I received such a low score. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
