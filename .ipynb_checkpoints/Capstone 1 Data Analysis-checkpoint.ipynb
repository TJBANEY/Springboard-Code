{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 34px; margin-bottom: 2px; line-height: 0px;\">AirBnB - Capstone Project 1 Data Analysis</h1>\n",
    "<h3 style=\"line-height: 2px; font-style: italic;\"> Timothy Baney<h3>\n",
    "\n",
    "* <a href=\"#intro\" style=\"color: black; text-decoration: none;\">Introduction</a>\n",
    "* <a href=\"#import\" style=\"color: black; text-decoration: none;\">Import Libraries</a>\n",
    "* <a href=\"#data-structure\" style=\"color: black; text-decoration: none;\">Feature Engineering</a>\n",
    "    * <a href=\"#observ-variable\" style=\"color: black; text-decoration: none;\">Create Mapping functions</a>\n",
    "    * <a href=\"#missing-values\" style=\"color: black; text-decoration: none;\">One Hot Encoding</a>\n",
    "* <a href=\"#import\" style=\"color: black; text-decoration: none;\">Handle Missing Values</a>\n",
    "* <a href=\"#problem-nature\" style=\"color: black; text-decoration: none;\">Algorithms\n",
    "* <a href=\"#summary\" style=\"color: black; text-decoration: none;\">Summary</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p id=\"intro\" style=\"margin-bottom: 0px; line-height: 1px;\">Introduction</p>\n",
    "For this notebook, I am going to take the cleansed data that I have explored, and analyze how different machine learning algorithms perform on fitting a prediction model. I will first engineer the data so only key features are kept, and to make sure everything is numerical. I will than split my data to get a holdout set, train the analyzed algorithm on the training set of the data, and than score it with cross validation using 10 folds to find what the best algorithm is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p id=\"import\">Import Libraries</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timothybaney/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (7,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "import pylab\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from sklearn import datasets, tree, metrics, model_selection\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Perceptron\n",
    "from sklearn.feature_selection import SelectKBest, chi2, VarianceThreshold, RFE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pylab as pylab\n",
    "\n",
    "ucb_w_reindex = pd.read_csv('clean_airbnb.csv')\n",
    "ucb = pd.read_csv('clean_airbnb.csv')\n",
    "\n",
    "pylab.rcParams[ 'figure.figsize' ] = 12 , 5\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering - Create Mapping Functions \n",
    "Part of the feature engineering will include making functions to take multiple features in a column, and to return a new feature. One will get the time difference in days between signing up on the AirBnB site, and the users' first booking. Another will convert the date of the users' first booking, and return the season that the booking was made in. The others will see if the user language preference matches the destinations native language, and narrow all first browsers used to the top six browsers, and one browser titled 'other' to handle all other browsers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getTopBrowsers(row):\n",
    "    top_browsers = ['Chrome', 'Safari', 'Firefox', 'IE', 'Mobile Safari']\n",
    "    \n",
    "    if row['first_browser'] not in top_browsers:\n",
    "        return 'Other'\n",
    "    else:\n",
    "        return row['first_browser']\n",
    "    \n",
    "def getLapsedTime(row):\n",
    "    try:\n",
    "        account_creation = datetime.datetime.strptime(row['date_account_created'], '%Y-%m-%d')\n",
    "        first_booking = datetime.datetime.strptime(row['date_first_booking'], '%Y-%m-%d')\n",
    "        time_delta = first_booking - account_creation\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(row['id'])\n",
    "    \n",
    "    return time_delta.days\n",
    "\n",
    "lang_dict = {'en': 'eng', 'fr': 'fra', 'it': 'ita', 'es': 'spa', 'de': 'deu', 'nl': 'nld', 'pt': 'por'}\n",
    "\n",
    "def convertLang(row):\n",
    "    if row['language'] in lang_dict:\n",
    "        return lang_dict[row['language']]\n",
    "    else:\n",
    "        return row['language']\n",
    "    \n",
    "ucb['language'] = ucb.apply(lambda x: convertLang(x), axis=1)\n",
    "\n",
    "def langPrefMatch(row):\n",
    "    if row['language'] == row['destination_language ']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def getSeason(row):\n",
    "    seasons = {\n",
    "        '01': 'Winter',\n",
    "        '02': 'Winter',\n",
    "        '03': 'Spring',\n",
    "        '04': 'Spring',\n",
    "        '05': 'Spring',\n",
    "        '06': 'Summer',\n",
    "        '07': 'Summer',\n",
    "        '08': 'Summer',\n",
    "        '09': 'Autumn',\n",
    "        '10': 'Autumn',\n",
    "        '11': 'Autumn',\n",
    "        '12': 'Winter'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        return seasons[str(row['date_first_booking']).split('-')[1]]\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering - One Hot Encoding\n",
    "Before analyzing performance with various algorithms, it is important that we turn all of our categorical data into one hot encoding values. One hot encoding takes all the category values of a column, and makes them all their own unique column with a boolean value, a one, or a zero, that says whether or not that row is, or is not that category class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove all ghost rows \"Ones without IDs\"\n",
    "ucb = ucb[~ucb['id'].isnull()]\n",
    "\n",
    "# Remove Country Destination One Hot Values used in Data Story\n",
    "ucb = ucb.drop(['US', 'FR', 'IT', 'GB', 'ES', 'CA', 'DE', 'NL', 'AU', 'PT'], axis=1)\n",
    "\n",
    "# Remove rows where the user never booked a trip, since this won't provide any value for \n",
    "# Country predictions\n",
    "ucb = ucb.loc[ucb['country_destination'] != 'NDF']\n",
    "\n",
    "# Create Language Matches Column\n",
    "ucb['lang_match'] = ucb.apply(lambda x: langPrefMatch(x), axis=1)\n",
    "\n",
    "# Remove attributes that are directly related to the country e.g. Latitude, Longitude\n",
    "ucb = ucb.drop(['lat_destination', 'lng_destination', 'timestamp_first_active'], axis=1)\n",
    "ucb = ucb.drop(['language_levenshtein_distance', 'id'], axis=1)\n",
    "ucb = ucb.drop(['language', 'destination_language ', 'destination_km2', 'distance_km'], axis=1)\n",
    "\n",
    "# Create Season Booked One Hot Columns [Autumn, Winter, Spring, Summer]\n",
    "ucb['season_booked'] = ucb.apply(lambda x: getSeason(x), axis=1)\n",
    "\n",
    "# Turn Seasons into one hot encoding values\n",
    "season = pd.get_dummies(ucb['season_booked'])\n",
    "ucb = ucb.join(season)\n",
    "ucb = ucb.drop('season_booked', axis=1)\n",
    "\n",
    "# Get most prevalant browsers used, labeling all other browsers as other\n",
    "ucb['first_browser'] = ucb.apply(lambda x: getTopBrowsers(x), axis=1)\n",
    "\n",
    "# Turn gender into one hot encoding values \"Male, Female\"\n",
    "ucb = ucb[(ucb['gender'] == 'male') | (ucb['gender'] == 'female')]\n",
    "gender_oh = pd.get_dummies(ucb['gender'])\n",
    "ucb = ucb.join(gender_oh)\n",
    "ucb = ucb.drop('gender', axis=1)\n",
    "\n",
    "# Turn signup method into one hot encoding values\n",
    "su_method = pd.get_dummies(ucb['signup_method'])\n",
    "ucb = ucb.join(su_method)\n",
    "ucb = ucb.drop('signup_method', axis=1)\n",
    "ucb = ucb.rename(columns={'basic': 'signup_basic', 'facebook': 'signup_facebook', 'google': 'signup_google'})\n",
    "\n",
    "# Turn signup app into one hot encoding values\n",
    "su_app = pd.get_dummies(ucb['signup_app'])\n",
    "ucb = ucb.join(su_app)\n",
    "ucb = ucb.drop('signup_app', axis=1)\n",
    "\n",
    "# Turn first device type into one hot encoding values\n",
    "dev_type = pd.get_dummies(ucb['first_device_type'])\n",
    "ucb = ucb.join(dev_type)\n",
    "ucb = ucb.drop('first_device_type', axis=1)\n",
    "\n",
    "# Turn affiliate channel into one hot encoding values\n",
    "af_channel = pd.get_dummies(ucb['affiliate_channel'])\n",
    "ucb = ucb.join(af_channel)\n",
    "ucb = ucb.drop('affiliate_channel', axis=1)\n",
    "ucb = ucb.rename(columns={'api': 'ch_api', 'content': 'ch_content', 'direct': 'ch_direct',\n",
    "                          'other': 'ch_other', 'remarketing': 'ch_remarketing', 'sem-brand': 'ch_sem_brand',\n",
    "                          'sem-non-brand': 'ch_sem_non_brand', 'seo': 'ch_seo'})\n",
    "\n",
    "# Turn affiliate provider into one hot encoding values\n",
    "af_provider = pd.get_dummies(ucb['affiliate_provider'])\n",
    "ucb = ucb.join(af_provider)\n",
    "ucb = ucb.drop('affiliate_provider', axis=1)\n",
    "\n",
    "# Turn first affiliate tracked into one hot encoding values\n",
    "fa_oh = pd.get_dummies(ucb['first_affiliate_tracked'])\n",
    "ucb = ucb.join(fa_oh)\n",
    "ucb = ucb.drop('first_affiliate_tracked', axis=1)\n",
    "\n",
    "# Turn first browser into one hot encoding values\n",
    "fbwsr_oh = pd.get_dummies(ucb['first_browser'])\n",
    "ucb = ucb.join(fbwsr_oh)\n",
    "ucb = ucb.drop('first_browser', axis=1)\n",
    "\n",
    "# Create 'AccountCreation-BookingTime' column for difference\n",
    "ucb['days_to_book'] = ucb.apply(lambda x: getLapsedTime(x), axis=1)\n",
    "\n",
    "# Remove date_account_created, and first_booking columns\n",
    "ucb = ucb.drop(['date_account_created', 'date_first_booking'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Missing Values\n",
    "Our data still has some missing values. to fix this we will simply remove the rows with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59714\n",
      "15532\n"
     ]
    }
   ],
   "source": [
    "print(ucb['Web'].count())\n",
    "ucb = ucb.loc[~ucb['actions_total_count'].isnull()]\n",
    "ucb = ucb.loc[~ucb['average_action_duration'].isnull()]\n",
    "ucb = ucb.loc[~ucb['dest_age_pop'].isnull()]\n",
    "print(ucb['Web'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = ucb.drop('country_destination', axis=1)\n",
    "y = ucb['country_destination'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Holdout Data\n",
    "\n",
    "The get a more accurate scoring of the algorithms used, we will seperate our data by a 30/70 split, the 30% being the 'holdout' data. The holdout data isn't used to train any models, and doesn't include the target feature, so it simulates unseen data to the model. We will also cross validate on ten folds to ensure the most precise measure of performance for each algorithm we can. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 1 - KNearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9500057714942598"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "knn_score = knn.score(X_test, y_test)\n",
    "knn_fold_score = model_selection.cross_val_score(knn, X_test, y_test, cv=10).mean()\n",
    "knn_fold_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 2 - Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98650441234251862"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "dt_score = dtree.score(X_test, y_test)\n",
    "dt_fold_score = model_selection.cross_val_score(dtree, X_test, y_test, cv=10).mean()\n",
    "dt_fold_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 3 - Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93415195676023066"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_score = rf.score(X_test, y_test)\n",
    "rf_fold_score = model_selection.cross_val_score(rf, X_test, y_test, cv=10).mean()\n",
    "rf_fold_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 4 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8938056469778124"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "lr_score = logreg.score(X_test, y_test)\n",
    "lr_fold_score = model_selection.cross_val_score(logreg, X_test, y_test, cv=10).mean()\n",
    "lr_fold_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 5 - Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91441572355861089"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaus = GaussianNB()\n",
    "gaus.fit(X_train, y_train)\n",
    "\n",
    "gaus_score = gaus.score(X_test, y_test)\n",
    "gaus_fold_score = model_selection.cross_val_score(gaus, X_test, y_test, cv=10).mean()\n",
    "gaus_fold_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 6 - Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91441572355861089"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grd = GradientBoostingClassifier()\n",
    "grd.fit(X_train, y_train)\n",
    "\n",
    "grd_score = grd.score(X_test, y_test)\n",
    "gaus_fold_score = model_selection.cross_val_score(gaus, X_test, y_test, cv=10).mean()\n",
    "gaus_fold_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 7 - Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8148258083366009"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per = Perceptron()\n",
    "per.fit(X_train, y_train)\n",
    "\n",
    "per_score = per.score(X_test, y_test)\n",
    "per_fold_score = model_selection.cross_val_score(per, X_test, y_test, cv=10).mean()\n",
    "per_fold_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Method 1 - Voting Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting = VotingClassifier(estimators=[('knn', knn), ('dtree', dtree), ('grd', grd)], voting='soft')\n",
    "voting.fit(X_train, y_train)\n",
    "voting_score = voting.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Voting Ensemble', 'score': 0.99399141630901289},\n",
       " {'name': 'Gradient Boosting', 'score': 0.99248927038626611},\n",
       " {'name': 'Decision Trees', 'score': 0.98650441234251862},\n",
       " {'name': 'KNearest Neighbors', 'score': 0.9500057714942598},\n",
       " {'name': 'Random Forests', 'score': 0.93415195676023066},\n",
       " {'name': 'Gaussian Naive Bayes', 'score': 0.91441572355861089},\n",
       " {'name': 'Logistic Regression', 'score': 0.8938056469778124},\n",
       " {'name': 'Perceptron', 'score': 0.8148258083366009}]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm_scores = [\n",
    "    {'name': 'KNearest Neighbors', 'score': knn_fold_score},\n",
    "    {'name': 'Decision Trees', 'score': dt_fold_score},\n",
    "    {'name': 'Random Forests', 'score': rf_fold_score},\n",
    "    {'name': 'Logistic Regression', 'score': lr_fold_score},\n",
    "    {'name': 'Gaussian Naive Bayes', 'score': gaus_fold_score},\n",
    "    {'name': 'Gradient Boosting', 'score': grd_score},\n",
    "    {'name': 'Perceptron', 'score': per_fold_score},\n",
    "    {'name': 'Voting Ensemble', 'score': voting_score}\n",
    "]\n",
    "    \n",
    "\n",
    "alg_scores = sorted(algorithm_scores, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "alg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Voting Ensemble</td>\n",
       "      <td>0.993991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.992489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Trees</td>\n",
       "      <td>0.986504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNearest Neighbors</td>\n",
       "      <td>0.950006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forests</td>\n",
       "      <td>0.934152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.914416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.893806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.814826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name     score\n",
       "0       Voting Ensemble  0.993991\n",
       "1     Gradient Boosting  0.992489\n",
       "2        Decision Trees  0.986504\n",
       "3    KNearest Neighbors  0.950006\n",
       "4        Random Forests  0.934152\n",
       "5  Gaussian Naive Bayes  0.914416\n",
       "6   Logistic Regression  0.893806\n",
       "7            Perceptron  0.814826"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(alg_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
